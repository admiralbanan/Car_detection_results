# Этап № 4 — Создание прототипа нейросети и получение первой точности распознавания



## Краткое резюме (Abstract)

Цель этапа — создать рабочий прототип нейросетевой системы, способной распознавать марку/модель автомобиля по кадру видеозаписи и демонстрирующей первую воспроизводимую точность распознавания. В качестве прототипа используется классификатор на базе EfficientNet-B0, обученный на собственном датасете (3 целевых класса + класс background). Результат: валидационная точность прототипа достигает **99.27%**, что позволяет утверждать реализуемость задачи и переход к этапам финализации (увеличение устойчивости, трекинг, GPS-привязка).

---

## 1. Тема и постановка задачи

**Тема:** «Классификация марок/моделей автомобилей на кадрах видеозаписи с дальнейшей возможностью GPS-привязки и анализа поведения».  
**Задача этапа:** разработать и верифицировать прототип нейронной сети, который на вход получает кадр (из видео) и выдаёт один из следующих классов: `audi_a6_c4`, `shkoda_fabia`, `uaz_images`, `background`. Результат должен подтверждать, что задача реализуема и что модель может быть интегрирована в дальнейшую систему с привязкой по GPS.

---

## 2. Описание базы данных (Dataset)

**Общая информация:**
- Тип данных: статические кадры (извлечённые из видео и других источников, например: авито, авто.ру, гугл фото, яндекс картинки, итд.) в форматах JPEG/PNG.
- Количество целевых изображений: **6283** (три целевых класса).
- Количество фоновых изображений (background): **>3500** (используются для повышения устойчивости).
- Всего: ~9800+ файлов (включая background), размер фоновых — >3.5 GB (не входит в публичный репозиторий по соображениям размера).
- Ссылка на датасет: https://github.com/admiralbanan/Car_detection
- Источник данных: открытые источники
  - GoPro видео с поездок на самокате по городу
  - https://www.avito.ru
  - https://www.drive2.ru
  - https://yandex.ru/images
  - Yotube
  - Google images
- Инструмент сбора: ShareX (ручная разметка скриншотов и кадров из видео) 
- Структура директорий (используемая в тренировке):

```
dataset/
 ├── train/
 │   ├── audi_a6_c4/
 │   ├── shkoda_fabia/
 │   ├── uaz_images/
 │   └── background/
 ├── val/
 │   ├── audi_a6_c4/
 │   ├── shkoda_fabia/
 │   ├── uaz_images/
 │   └── background/
 └── test/
 │   ├── audi_a6_c4/
 │   ├── shkoda_fabia/
 │   ├── uaz_images/
 │   └── background/
```

**Числа по сплитам (используемые при обучении):**
- `train`: 5623 изображений
- `val`: 490 изображений
- `test`: 170 изображений


---

## 3. Параметризация данных и предобработка

### 3.1 Размер входных данных
Все изображения независимо от исходного размера приводятся к пространственному разрешению:

- **500 × 500 пикселей**

Это необходимо для корректной работы EfficientNet-B0, вход которой допускает произвольный размер, но оптимальное качество достигается при квадратных изображениях среднего разрешения.

### 3.2 Нормализация
Используется стандартная нормализация:

- **mean = [0.485, 0.456, 0.406]**
- **std  = [0.229, 0.224, 0.225]**

Это параметры ImageNet, т.к. обучаемая модель — **предобученная EfficientNet-B0 (IMAGENET1K_V1)**.

### 3.3 Аугментации (только train)
Для повышения обобщающей способности применяются мягкие аугментации:

- `RandomHorizontalFlip(p=0.001)` — очень низкая вероятность, т.к. зеркальный вид автомобиля редко встречается.
- `RandomRotation(±10°)` — компенсирует неточную разметку и наклон камеры.
- `ColorJitter` (яркость/контрастность) — улучшает устойчивость к погоде/времени суток.
- `RandomAffine` (в ранних версиях — отключено, будет добавлено позднее).
- Приведение изображения к тензору (`ToTensor`).
- Нормализация по ImageNet.

Аугментации подобраны так, чтобы **не искажать форму автомобиля**, но достаточны для повышения точности.

### 3.4 Параметры загрузчика данных
- **Batch size**: 16–32 (зависит от доступной локальной видеопамяти).
- **Shuffle = True** — только для `train`.


## 4. Архитектура нейросети и настройка обучения

### 4.1 Базовая архитектура
В качестве основы использована сверточная нейросеть **EfficientNet-B0**, предобученная на датасете ImageNet (*IMAGENET1K_V1*).  
Она обеспечивает оптимальный баланс между точностью и вычислительной эффективностью, что важно при ограниченном объёме данных.

### 4.2 Модификации модели
Для решения задачи многоклассовой классификации (4 класса) выполнены следующие изменения:

- Удалён исходный классификатор.
- Добавлен новый `Linear(in_features, 4)` — выход по числу классов.
- Функция активации — **softmax** (в составе `CrossEntropyLoss`).
- Dropout 0.2–0.3 (встроенный в EfficientNet backbone) обеспечивает устойчивость к переобучению.

### 4.3 Гиперпараметры и настройки обучения
- **Loss-функция:** `CrossEntropyLoss`
- **Оптимизатор:** `Adam` (экспериментально также применялся `AdamW`)
- **LR Scheduler:** при необходимости — `ReduceLROnPlateau` или `CosineAnnealing`
- **Weight decay:** `1e-5`
- **Batch size:** 16–32
- **Количество эпох:** варьировалось от 50 до 100 в разных экспериментах  
  Финальная модель — результат серии итераций до стабильного достижения **99%+** точности на валидации.
- **Early stopping:** остановка при отсутствии улучшения **20 эпох** подряд (мониторинг точности).

### 4.4 Причины выбора EfficientNet-B0
- Высокая точность при минимальном количестве параметров.
- Оптимизированная архитектура (MBConv + compound scaling).
- Отлично подходит для **transfer learning**, особенно при ограниченном размере выборки.
- Компактная, быстрая, не требует больших GPU-ресурсов.



---

## 5. Графическое подтверждение

В процессе обучения была реализована итеративная стратегия — добавление данных классов, увеличение аугментаций, изменение LR.
Для формирования статистики и формирования новых изображений классов использовались скачанные видеозаписи, найденные на youtubе.соm. Этот процесс шел итеративно. Пока другие видео скачивались - набирался датасет из классифицированных (ошибочно или нет, определялось вручную) изображений с видео. Ниже представлена гистограмма используемых за все итерации видеозаписей:
![Гистограмма длительности видео](results/video_statistic.jpg)

**Анализ**:  
- Основная масса видео — **до 20 минут**  
- Самое длинное — **98 минут** (трасса)  
- Короткие ролики (~10 мин) — городские, загородные поездки  
- Распределение **мультимодальное** — отражает разные сценарии съёмки (освещенность, время года, итд.)


**Примечания:**
- Background собирался из кадров, на которых отсутствуют целевые объекты или классификация дала «мусорные» кадры — это улучшает устойчивость модели к ложным срабатываниям.
После набора датасета и получения первой точности был проведен эксперимент по минимальному разрешению изображения для успешного решения задачи классификации:

| Итерация | Описание изменений | Val Accuracy |
|----------|---------------------|--------------|
| 1        | Базовое обучение, минимальная аугментация, 200х200 | 72.93% |
| 2        | Добавлены фоновые кадры (background), 300х300 | 87.91% |
| 3        | Добавлены фоновые кадры (background) и кадры классов с видео, 400х400 | 96.62% |
| 4        | Финальный прогон, early stopping, 500х500 | **99.27%** |

> Итерации документированы в ноутбуках и скриптах.




#### График прогресса (как пример) для 97% точности
![Прогресс обучения](results/training_progress.png)  
*Потери резко падают, точность достигает 96.62%, после повторного обучения достигается точность 99.27%*

#### Матрица ошибок (валидация)
![Матрица ошибок](results/confusion_matrix.png)  

#### Гистограмма количества ошибок классификации на видео
![Гистограмма ошибок](results/error_statistic.jpg)

**Анализ**:  
- **Пик в 0–10 ошибок** — большинство видео классифицируются **почти идеально**  
- Высокий столбец слева — **почти 60 видео с 0-10 ошибок**  
- Длинный правый хвост до 80 — **единичные сложные ролики**  
- **Вывод**: модель **практически не ошибается** на типичных видео, ошибки сосредоточены в сложных условиях.

#### Probability Plot (Q-Q Plot) — проверка нормальности распределения ошибок классификации
![Q-Q Plot ошибок](results/probabilty.jpg)

**Анализ**:  
- **Центральная часть** (до ±20 ошибок) — **линейная**, ошибки распределены **почти нормально**  
- **Хвосты отклоняются**:  
  - **Левый**: меньше ожидаемого — нет видео с отрицательным числом ошибок (очевидно)
  - **Правый**: больше ожидаемого — **тяжёлый хвост**, есть видео с аномально большим числом ошибок  
- Параметры: μ ≈ 5.57, σ ≈ 11.18  
- **Вывод**: **ошибки не строго нормальны**, но **центр стабилен** — можно использовать среднее/медиану для оценки типичной ошибки.


---

## 6. Ноутбуки



https://colab.research.google.com/drive/1LoKwLRK15UTvwQn1D55FhC6I42sD6XsK?usp=sharing

https://colab.research.google.com/drive/1jxEvqVKpAxKdSVzx40JFkz5uHQHt_knr?usp=sharing

https://colab.research.google.com/drive/1hX6BXThc8tKOH8yMcSEViFwV7HbDsPUq?usp=sharing

https://colab.research.google.com/drive/1BHKDJZjBrRH90H9jLW7cErgLKYQxR3q7?usp=sharing

---


---

## 7. Выводы

- Успешно создан и обучен прототип классификатора марок/моделей автомобилей  
- Использована предобученная **EfficientNet-B0** (ImageNet1K_V1) с заменой под 4 класса  
- Сформирован и опубликован собственный датасет: **~9800+ изображений** (3 целевых класса + background)  
- Достигнута **валидационная точность 99.27 %** при входном разрешении 500×500  
- Модель демонстрирует высокую устойчивость к ложным срабатываниям благодаря большому объёму фоновых кадров  
- На реальных тестовых видео (10–20 мин) медианное число ошибок — **3–5**  

**Задача классификации решена, подтверждена реализуемость проекта.**


---
## План дальнейшей работы (Этап №5 + финализация диплома)

1. **Финальное подтверждение качества классификатора**  
   - Собрать 10–30 новых видео из интернета + снять свои зимние ролики (снег, ночь, засветы фар, грязные машины).
   - Ручная проверка ошибок модели на этих видео, понять, где основные промахи  
   - При необходимости добрать сложные кадры в датасет и довести точность до стабильных 90–97 % на свежих видео
   - Либо сформировать обоснованные ограничения работы классифицкатора (скорее всего, ночные кадры, модель не сможет классифировать так же хорошо)  

2. **Автоматизация обработки видео**  
   - Написать скрипт (прототип уже есьт, не опубликован пока что):  
     – покадровый проход по видео  
     – ресайз кадра → инференс EfficientNet-B0 (400×400 или 500×500)  
     – фильтрация по confidence ≥ 0.95
     – вывод в CSV/JSON (время + класс + точность)

3. **Синхронизация с GPS-треком**  
   - Определить формат лог-файла GPS-трекера (сейчас GPS работает оочень нестабильно, большинство GPS-логов не информативны)
   - Написать парсер: сопоставление времени видео ↔ координаты GPS с точностью ±1-2 сек  
   - Итоговый CSV/JSON: `время | lat | lon | марка_модель | confidence`  

4. **Простая веб-демонстрация (минимальный рабочий прототип)**  
   - Flask/FastAPI + одна-две HTML-странички  
   - Функционал:  
     • Загрузка CSV/JSON + Кадры
     • Отображение кадров найденных классов на карте (например яндекс)
     • С дизайном у меня плохо, поэтому, будет минимализм


